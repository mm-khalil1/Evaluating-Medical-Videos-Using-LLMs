{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')  # Add the parent directory of LLM_Evaluations to the Python path\n",
    "from Utils.llm_evaluation_utils import load_responses_df, \\\n",
    "                        check_and_store_response,    \\\n",
    "                        build_question_prompt,      \\\n",
    "                        QUESTION_SETS\n",
    "\n",
    "api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "safety_settings = [\n",
    "    {\n",
    "        'category': 'HARM_CATEGORY_DANGEROUS',\n",
    "        'threshold': 'BLOCK_NONE',\n",
    "    },\n",
    "    {\n",
    "        'category': 'HARM_CATEGORY_HARASSMENT',\n",
    "        'threshold': 'BLOCK_NONE',\n",
    "    },\n",
    "    {\n",
    "        'category': 'HARM_CATEGORY_HATE_SPEECH',\n",
    "        'threshold': 'BLOCK_NONE',\n",
    "    },\n",
    "    {\n",
    "        'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n",
    "        'threshold': 'BLOCK_NONE',\n",
    "    },\n",
    "    {\n",
    "        'category': 'HARM_CATEGORY_DANGEROUS_CONTENT',\n",
    "        'threshold': 'BLOCK_NONE',\n",
    "    },\n",
    "]\n",
    "\n",
    "generation_config = {\n",
    "  'temperature': 0.8,\n",
    "  'top_p': 1,\n",
    "  'top_k': 8,\n",
    "  'max_output_tokens': 250,\n",
    "}\n",
    "\n",
    "model_name = 'gemini-1.0-pro-latest'\n",
    "model = genai.GenerativeModel(model_name=model_name,\n",
    "                              safety_settings=safety_settings,\n",
    "                            #   system_instruction=system,          # only in 1.5-pro\n",
    "                              generation_config=generation_config)\n",
    "question_type = 'GS'\n",
    "QUESTIONS = QUESTION_SETS[question_type]['QUESTIONS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Gemini Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_errors_dict(dir, model_name):\n",
    "    '''Load and prepare a dictionary of IDs and question numbers with Blocked errors from a JSON file.'''\n",
    "    if '1.0' in model_name:\n",
    "        errors_file_name = 'ids_nums_with_Blocked_error-Gemini-1_0.json'\n",
    "    elif '1.5' in model_name:\n",
    "        errors_file_name = 'ids_nums_with_Blocked_error-Gemini-1_5.json'\n",
    "        \n",
    "    file_path = os.path.join(dir, errors_file_name)\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            ids_questions_with_error = json.load(f)\n",
    "        # Convert the lists to sets\n",
    "        ids_questions_with_error = {key: set(value) for key, value in ids_questions_with_error.items()}\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        ids_questions_with_error = {}\n",
    "    \n",
    "    return ids_questions_with_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcripts_dir = '../../Getting_Transcripts'\n",
    "# transcripts_file_name = 'merged_filtered_videos_transcripts.csv'\n",
    "# responses_dir = '../LLMs_Responses'\n",
    "# topics_to_include = ['Spina Bifida', 'Flat Feet', 'Cluster Headache', 'Trigger Finger', 'Pudendal Nerve']\n",
    "\n",
    "transcripts_dir = '../../../ISA_Paper/Data'\n",
    "transcripts_file_name = 'diabetes_videos_transcripts.csv'\n",
    "responses_dir = '../../../ISA_Paper/Data/Results'\n",
    "topics_to_include = ['Insulin Self-Administration']\n",
    "\n",
    "prompt_type = 'GS_prompting'\n",
    "topics = 'diabetes'\n",
    "results_file_name = f'{model_name}-{topics}-{prompt_type}'\n",
    "\n",
    "responses_df = load_responses_df(transcripts_dir, transcripts_file_name, responses_dir, results_file_name, question_type)\n",
    "\n",
    "ids_questions_with_error = prepare_errors_dict('.', model_name)\n",
    "\n",
    "print('responses_df shape:', responses_df.shape)\n",
    "responses_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter to include selected topics only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Topic' not in responses_df.columns:\n",
    "    experts_file = '../../../Videos_and_DISCERN_data/filtered_experts_scores.csv'\n",
    "    experts_df = pd.read_csv(experts_file)\n",
    "\n",
    "    responses_df = responses_df.merge(experts_df[['Video ID', 'Topic']], on='Video ID', how='left')\n",
    "    responses_df.insert(2, 'Topic', responses_df.pop('Topic'))\n",
    "    responses_df = responses_df[responses_df['Topic'].isin(topics_to_include)]\n",
    "    responses_df = responses_df.reset_index(drop=True)\n",
    "\n",
    "print('responses_df shape:', responses_df.shape)\n",
    "responses_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Gemini API Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content_with_backoff(model, prompt, max_retries=3, base_delay=2):\n",
    "    '''\n",
    "    Calls model.generate_content() with exponential backoff on rate limit errors.\n",
    "  \n",
    "    Args:\n",
    "        model: The model object used for content generation.\n",
    "        prompt: The prompt string for content generation.\n",
    "        max_retries: Maximum number of retries in case of rate limit errors.\n",
    "        base_delay: Base delay (in seconds) for exponential backoff.\n",
    "  \n",
    "    Returns:\n",
    "        The response object from model.generate_content() on successful generation,\n",
    "        or None if all retries fail.\n",
    "        Raise an error if error occured other than error code 429 \n",
    "    '''\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            if response.text:\n",
    "                return response\n",
    "        except Exception as error:\n",
    "            if getattr(error, 'code', None) == 429:\n",
    "                print(f'Rate limit exceeded. Attempt {attempt}/{max_retries}...')\n",
    "                delay = base_delay * 2 ** (attempt - 1)  # Exponential backoff calculation\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                raise error # Raise the error for handling in the outer loop\n",
    "            \n",
    "    print(f'Failed to generate content after {max_retries} retries.')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_response = False\n",
    "\n",
    "# Calculate the delay based on your rate limit\n",
    "requests_limit_per_minute = 15\n",
    "base_delay = 60.0 / requests_limit_per_minute\n",
    "\n",
    "def gemini_inference(responses_df, QUESTIONS, base_delay, print_response):\n",
    "    for index, row in responses_df.iterrows():\n",
    "        video_id = row['Video ID']\n",
    "        transcript = row['Transcript']\n",
    "        print(f'Started with video ID: {video_id} | Index: {index}')\n",
    "        \n",
    "        for question_num in range(1, len(QUESTIONS) + 1):\n",
    "            column_name = f'Response_{question_num}'\n",
    "            if row[column_name] == '':\n",
    "\n",
    "                # Check if the question_num for the video_id has already encountered an error\n",
    "                # if question_num in ids_questions_with_error.get(video_id, set()):\n",
    "                #     # print(f'Skipping video ID: {video_id} | Index: {index} | Question: {question_num} due to previous error')\n",
    "                #     continue\n",
    "                \n",
    "                prompt = build_question_prompt(transcript, question_num, question_type)\n",
    "\n",
    "                try:\n",
    "                    # response = model.generate_content(prompt)\n",
    "                    response = generate_content_with_backoff(model, prompt, max_retries=3, base_delay=base_delay)\n",
    "                    if response:\n",
    "                        check_and_store_response(response.text, responses_df, video_id, question_num, \n",
    "                                                 print_response=print_response)\n",
    "                    else:\n",
    "                        return\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f'Error with video ID {video_id}, index {index}, Q{question_num}: {e}')\n",
    "                    if 'candidate.safety_ratings' in str(e) or 'response.prompt_feedback' in str(e):    # BlockedPromptException\n",
    "                        if video_id not in ids_questions_with_error:\n",
    "                            ids_questions_with_error[video_id] = set()  # Initialize the set if it's the first occurrence of the video ID\n",
    "                        ids_questions_with_error[video_id].add(question_num)\n",
    "                        continue\n",
    "                    \n",
    "                time.sleep(base_delay)\n",
    "\n",
    "gemini_inference(responses_df, QUESTIONS, base_delay, print_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_from_index = 0\n",
    "index_of_q1 = responses_df.columns.get_loc(\"Q1\")\n",
    "\n",
    "responses_df.iloc[display_from_index:, index_of_q1:index_of_q1+15].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of errors: ', len(ids_questions_with_error))\n",
    "ids_questions_with_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_none = (responses_df.isna() | (responses_df == '')).sum()\n",
    "columns_with_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_none = responses_df[responses_df.isna().any(axis=1)]\n",
    "rows_with_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_with_problems = responses_df[responses_df['Problem'].apply(lambda x: len(x) > 0)].index.tolist()\n",
    "print(indices_with_problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "if indices_with_problems:\n",
    "    index_with_problem = 29\n",
    "    responses_with_problem_list = list(responses_df.loc[index_with_problem, 'Problem'])\n",
    "    print(\"List of questions with problem:\", responses_with_problem_list)\n",
    "\n",
    "    response_with_problem = responses_with_problem_list[0]\n",
    "    text = responses_df.loc[index_with_problem, f'Response_{response_with_problem}']\n",
    "    display(HTML(\"<div style='white-space: pre-wrap;'>{}</div>\".format(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the full responses for a specific transcript\n",
    "index_to_display = 51\n",
    "for question_num in range(1, 16):\n",
    "    print(f'Q{question_num}:', responses_df.at[index_to_display,f'Response_{question_num}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Errors to JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_encoder(obj):\n",
    "    if isinstance(obj, set):\n",
    "        return list(obj)        # convert sets to lists\n",
    "    raise TypeError('Object of type set is not JSON serializable')\n",
    "\n",
    "# save ids and questions number that encountered errors\n",
    "if '1.0' in model_name:\n",
    "    errors_file_name = 'ids_nums_with_Blocked_error-Gemini-1_0.json'\n",
    "elif '1.5' in model_name:\n",
    "    errors_file_name = 'ids_nums_with_Blocked_error-Gemini-1_5.json'\n",
    "with open(errors_file_name, 'w') as f:\n",
    "    json.dump(ids_questions_with_error, f, default=set_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Results in a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_output_file = os.path.join(responses_dir, f'{results_file_name}-response.csv')\n",
    "\n",
    "responses_df.to_csv(csv_output_file, index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
